{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input loading Time: 2.294711 seconds ---\n",
      "Training Tot instances: 2002\n",
      "Test Tot instances: 1186\n",
      "+-----+--------------------+-----+\n",
      "|label|            features|class|\n",
      "+-----+--------------------+-----+\n",
      "|  1.0|(240,[2,6,10,13,1...|  1.0|\n",
      "|  1.0|(240,[3,6,9,14,17...|  1.0|\n",
      "|  1.0|(240,[0,6,8,12,17...|  0.0|\n",
      "|  1.0|(240,[2,6,9,15,18...|  1.0|\n",
      "|  1.0|(240,[1,7,10,13,1...|  1.0|\n",
      "|  1.0|(240,[0,6,10,12,1...|  0.0|\n",
      "|  1.0|(240,[2,5,11,13,1...|  1.0|\n",
      "|  1.0|(240,[2,6,10,13,1...|  1.0|\n",
      "|  1.0|(240,[1,6,9,15,17...|  1.0|\n",
      "|  1.0|(240,[0,6,8,12,17...|  0.0|\n",
      "|  1.0|(240,[2,7,9,15,18...|  1.0|\n",
      "|  1.0|(240,[1,7,10,13,1...|  1.0|\n",
      "|  1.0|(240,[2,4,8,12,16...|  1.0|\n",
      "|  1.0|(240,[2,6,9,15,17...|  1.0|\n",
      "|  1.0|(240,[2,6,10,13,1...|  1.0|\n",
      "|  1.0|(240,[3,6,9,15,17...|  1.0|\n",
      "|  1.0|(240,[0,6,8,12,17...|  0.0|\n",
      "|  1.0|(240,[2,6,9,15,18...|  1.0|\n",
      "|  1.0|(240,[1,7,10,13,1...|  0.0|\n",
      "|  1.0|(240,[2,4,8,12,16...|  1.0|\n",
      "+-----+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Accuracy =  0.954468802698145\n"
     ]
    }
   ],
   "source": [
    "def encodeDNASeq(seq, encoding='OneHot'):\n",
    "    \"\"\"Encode nucleotides from character to double or OneHot encoding.\n",
    "    Using OneHot nucleotides are encoded as:\n",
    "    A->1000; C->0100; G->0010; T->0001; other->0000\n",
    "    Using Index as: A->1.0; C->2.0; G->3.0; t->4.0; other->0.0\n",
    "    @param: seq A string containing a sequence of nucleotides \n",
    "    @param: encoding_type output encodig: OneHot or Index\n",
    "\n",
    "    \"\"\"    \n",
    "    if encoding==\"Index\":\n",
    "        mymap = {'A':1.0, 'C':2.0, 'G':3.0, 'T':4.0, 'N':0.0}\n",
    "\n",
    "    else:\n",
    "        mymap ={'A':SparseVector(4, [0], [1]), \n",
    "                'C':SparseVector(4, [1], [1]), \n",
    "                'G':SparseVector(4, [2], [1]), \n",
    "                'T':SparseVector(4, [3], [1]), \n",
    "                'N':SparseVector(4,[0],[0])}    \n",
    "    \n",
    "    indexed_seq=list()\n",
    "    for n in seq:\n",
    "       indexed_seq.append(mymap.get(n) if n in mymap else SparseVector(4, [0], [0]))\n",
    "    return indexed_seq   \n",
    "\n",
    "\n",
    "#Split each line in single features\n",
    "#encode each nucleotide using function encodeDNASeq\n",
    "def load_dna_dataset(file_name, label_value=1.0, nrows=0, encoding='OneHot', setLabel=True):\n",
    "    \"Read Input Dataset contained in file_name. Data are labelled with value specified in label_value parameter\"\n",
    "    rdd = sc.textFile(file_name).flatMap(lambda line: [list(line)]).map(lambda s: encodeDNASeq(s,encoding)) \n",
    "        \n",
    "    #Insert Label Column and convert Rdd into Dataframe in order to apply ML Algorithm\n",
    "    df = rdd.toDF()\n",
    "    if (setLabel): df = df.withColumn(\"label\",lit(label_value)) \n",
    "        \n",
    "    return df\n",
    "\n",
    "#Inizialize Spark Context\n",
    "import findspark\n",
    "findspark.init(\"/home/osboxes/spark-2.3.1-bin-hadoop2.7\")\n",
    "\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import time\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Load external Jar\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = ' --jars /home/osboxes/brainscala/target/scala-2.11/brain-scala-utils_2.11-1.0.jar pyspark-shell'\n",
    "\n",
    "\n",
    "#Create Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"test\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "#Training set Load\n",
    "#The input dataset is divided in 4 files: Positive instances and negative instances for Training and Test set\n",
    "#Each row of dataset cointains a string of nucleotides: A G C T.\n",
    "#We will load each line as a single experiment and each character as a feature. \n",
    "#The label of each row will be \"1\" for positive instances and \"0\" for negative ones\n",
    "start_time = time.time()\n",
    "\n",
    "#Read (Positive Instance) from file system into RDD.\n",
    "#training_set=load_dna_dataset(\"ipdata_tra_t_2018_toy.txt\",label_value=1.0)\n",
    "training_set=load_dna_dataset(\"ipdata_tra_t_2018.txt\",label_value=1.0)\n",
    "test_set=load_dna_dataset(\"ipdata_test_t_2018.txt\",label_value=1.0)\n",
    "\n",
    "#Read negative instances\n",
    "#neg_tra=load_dna_dataset(\"ipdata_tra_f_2018_toy.txt\",label_value=0.0)\n",
    "neg_tra=load_dna_dataset(\"ipdata_tra_f_2018.txt\",label_value=0.0)\n",
    "neg_test=load_dna_dataset(\"ipdata_test_f_2018.txt\",label_value=0.0)\n",
    "\n",
    "#Create training and test dataset\n",
    "training_set = training_set.union(neg_tra)\n",
    "test_set = test_set.union(neg_test)\n",
    "\n",
    "#Spark-ML algorithms requires a single vector containing each features\n",
    "#Assemble vector of features\n",
    "assembler = VectorAssembler(inputCols=training_set.columns[0:len(training_set.columns)-1],outputCol=\"features\")\n",
    "training=assembler.transform(training_set).select(\"label\",\"features\")\n",
    "#Note: we are unsing the same vector assembler instantiated for trainig set.\n",
    "test=assembler.transform(test_set).select(\"label\",\"features\")\n",
    "\n",
    "print(\"Input loading Time: %f seconds ---\" % (time.time() - start_time))\n",
    "print(\"Training Tot instances: %s\" %training.count())\n",
    "print(\"Test Tot instances: %s\" %test.count())\n",
    "\n",
    "training.filter(\"label=1.0\").createOrReplaceTempView(\"positivi\")\n",
    "training.filter(\"label=0.0\").createOrReplaceTempView(\"negativi\")\n",
    "\n",
    "positive = spark.sql(\"select features from positivi\")\n",
    "negative = spark.sql(\"select features from negativi\")\n",
    "\n",
    "#Train a model\n",
    "#The Scala static method BrainScalaMRBP.fit is invoked from SP-BRAIN linrary\n",
    "model = sc._jvm.brain.scala.BrainScalaMRBP.fit(positive._jdf , negative._jdf, False, True)\n",
    "\n",
    "model.saveModel(\"ipdata-model\")\n",
    "\n",
    "#Apply trained model on test set\n",
    "testClassified = model.transform(test._jdf)\n",
    "#Create a Dataframe\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrame\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "dfTestClassified = DataFrame(testClassified,sqlContext)\n",
    "\n",
    "dfTestClassified.show()\n",
    "\n",
    "#Computer accuracy\n",
    "accuracy = dfTestClassified.filter(\"label=class\").count()/dfTestClassified.count()\n",
    "print (\"Accuracy = \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
